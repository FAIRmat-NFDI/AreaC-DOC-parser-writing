{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"How to write a parser","text":"<p>NOMAD uses parsers to convert raw data (for example, output from computational software, instruments, or electronic lab notebooks) into NOMAD's common Archive format. The following pages describe how to develop such a parser and integrate it within the NOMAD software. The goal is equip users with the required knowledge to contribute to and extend NOMAD.</p>"},{"location":"#getting-started","title":"Getting started","text":"<p>In principle, it is possible to develop a \"local parser\" that uses the nomad-lab package to parse raw data, without changing the NOMAD software itself. This allows a quick start for focusing on the parsing of the data itself, but is not relevant for full integration of your new parser into NOMAD. Here we are focused on developing parsers that will be integrated into the NOMAD software. For this, you will have to install a development version of NOMAD.</p>"},{"location":"#parser-organization","title":"Parser organization","text":"<p>The NOMAD parsers can be found within your local NOMAD git repo under <code>dependencies/parsers/</code>. The parsers are organized into the following individual projects (<code>dependencies/parsers/&lt;parserproject&gt;</code>) with their own corresponding repositories:</p> <ul> <li>atomistic - Parsers for output from classical molecular simulations, e.g., from Gromacs, Lammps, etc.</li> <li>database - Parsers for various databases, e.g., OpenKim.</li> <li>eelsdb - Parser for the EELS database (https://eelsdb.eu/; to be integrated in the database project).</li> <li>electronic - Parsers for output from electronic structure calculations, e.g., from Vasp, Fhiaims, etc.</li> <li>nexus - Parsers for combining various instrument output formats and electronic lab notebooks.</li> <li>workflow - Parsers for output from codes that specialize in workflows, e.g., Aflow, FHI-vibes, QuantumEspressoPhonon, etc.</li> </ul> <p>Within each project folder you will find a <code>test/</code> directory, containing the parser tests, and also a directory containing the parsers' source code, <code>&lt;parserproject&gt;parser</code> or <code>&lt;parserproject&gt;parsers</code>, depending on if one or more parsers are contained within the project, respectively. In the case of multiple parsers, the files for individual parsers are contained within a corresponding subdirectory: <code>&lt;parserproject&gt;parsers/&lt;parsername&gt;</code> For example, the Quantum Espresso parser files are found in <code>dependencies/parsers/electronic/electronicparsers/quantumespresso/</code>.</p>"},{"location":"#setting-up-your-development-branches","title":"Setting up your development branches","text":"<p>We will first focus on the case of adding a new parser to an existing parser project. Creating a new parser project will require a few extra steps. The existing parser projects are stored within their own git repositories and then linked to the NOMAD software. All current parser projects are available at nomad-coe (see also individual links above).</p> <p>You will first need to create new branches within both the NOMAD project and also within the corresponding parser project. Ideally, this should be done following the best practices for NOMAD development. Here, we briefly outline the procedure:</p> <p>Create a new issue within the NOMAD project at NOMAD gitlab. On the page of the new issue, in the top right, click the arrow next to the <code>Create merge request</code> button and select <code>Create branch</code>. The branch name should be automatically generated with the corresponding issue number and the title of the issue (copy the branch name to the clipboard for use below), and the default source branch should be <code>develop</code>. Click the <code>Create branch</code> button.</p> <p>Now, run the following commands in your local NOMAD directory:</p> <p><code>git fetch --all</code> \u00a0\u00a0\u00a0\u00a0 (to sync with remote)</p> <p><code>git checkout origin/&lt;new_branch_name&gt; -b &lt;new_branch_name&gt;</code> \u00a0\u00a0\u00a0\u00a0 (to checkout the new branch and create a local copy of the branch)</p> <p>Unless you just installed the NOMAD development version, you should rerun <code>./scripts/setup_dev_env.sh</code> within the NOMAD directory to reinstall with the newest development branch.</p> <p>Now we need to repeat this process for the parser project that we plan to extend. As above, create a new issue at the relevant parser project GitHub page. Using the identical issue title as you did for the NOMAD project above is ideal for clarity. On the page of the new issue, in the right sidebar under the subsection <code>Development</code>, click <code>Create a branch</code>. As above, the branch name should be automatically generated with the corresponding issue number and the title of the issue, and the default source branch should be <code>develop</code> (which can be seen by clicking <code>change source branch</code>). Under <code>What's next</code>, the default option should be <code>Checkout locally</code>, which is what we want in this case. Click <code>Create branch</code>, and then copy the provided commands to the clipboard, and run them within the parser project folder within your local NOMAD repo, i.e., <code>dependencies/parsers/&lt;parserproject&gt;</code>.</p>"},{"location":"computational/","title":"Parser structure for computation","text":""},{"location":"computational/#overview-of-metadata-organization-for-computation","title":"Overview of metadata organization for computation","text":"<p>NOMAD stores all processed data in a well defined, structured, and machine readable format, known as the <code>archive</code>. The schema that defines the organization of (meta)data within the archive is known as the <code>MetaInfo</code>. More information can be found in the NOMAD docs: An Introduction to Schemas and Structured Data in NOMAD. The following diagram is an overarching visualization of the most important archive sections for computational data:</p> <pre><code>archive\n\u251c\u2500\u2500 run\n\u2502  \u00a0 \u251c\u2500\u2500 method\n\u2502  \u00a0 \u2502\u00a0\u00a0    \u251c\u2500\u2500 atom_parameters\n\u2502  \u00a0 \u2502\u00a0\u00a0    \u251c\u2500\u2500 dft\n\u2502  \u00a0 \u2502\u00a0\u00a0    \u251c\u2500\u2500 forcefield\n\u2502  \u00a0 \u2502      \u2514\u2500\u2500 ...\n\u2502  \u00a0 \u251c\u2500\u2500 system\n\u2502  \u00a0 \u2502\u00a0\u00a0    \u251c\u2500\u2500 atoms\n\u2502  \u00a0 \u2502\u00a0\u00a0    \u2502     \u251c\u2500\u2500 positions\n\u2502  \u00a0 \u2502\u00a0\u00a0    \u2502     \u251c\u2500\u2500 lattice_vectors\n\u2502  \u00a0 \u2502      \u2502     \u2514\u2500\u2500 ...\n\u2502  \u00a0 \u2502      \u2514\u2500\u2500 ...\n\u2502  \u00a0 \u2514\u2500\u2500 calculation\n\u2502  \u00a0        \u251c\u2500\u2500 energy\n\u2502  \u00a0        \u251c\u2500\u2500 forces\n\u2502  \u00a0        \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 workflow\n \u00a0\u00a0  \u251c\u2500\u2500 method\n \u00a0\u00a0  \u251c\u2500\u2500 inputs\n \u00a0\u00a0  \u251c\u2500\u2500 tasks\n \u00a0\u00a0  \u251c\u2500\u2500 outputs\n \u00a0\u00a0  \u2514\u2500\u2500 results\n</code></pre> <p>The most important section of the archive for computational data is the <code>run</code> section, which is divided into three main subsections: <code>method</code>, <code>system</code>, and <code>calculation</code>. <code>method</code> stores information about the computational model used to perform the calculation. <code>system</code> stores attributes of the atoms involved in the calculation, e.g., atom types, positions, lattice vectors, etc. <code>calculation</code> stores the output of the calculation, e.g., energy, forces, etc.</p> <p>The <code>workflow</code> section of the archive then stores information about the series of tasks performed to accumulate the (meta)data in the run section. The relevant input parameters for the workflow are stored in <code>method</code>, while the <code>results</code> section stores output from the workflow beyond observables of single configurations. For example, any ensemble-averaged quantity from a molecular dynamics simulation would be stored under <code>workflow/results</code>. Then, the <code>inputs</code>, <code>outputs</code>, and <code>tasks</code> sections are used to define the specifics of the workflow. For some standard workflows, e.g., geometry optimization and molecular dynamics, the NOMAD normalizers  will automatically populate these specifics. The parser must only create the appropriate workflow section.  For non-standard workflows, the parser (or more appropriately the corresponding normalizer) must populate these sections accordingly. More information about the structure of the workflow section, as well as instructions on how to upload custom workflows to link individual Entries in NOMAD, can be found in the Workflow DOCS</p>"},{"location":"computational/#recommended-parser-layout","title":"Recommended parser layout","text":"<p>The following represents the recommended core structure for a computational parser,  typically implemented within <code>&lt;parserproject&gt;/parser.py</code>.</p>"},{"location":"computational/#imports","title":"Imports","text":"<p>The imports typically include the necessary generic python modules, the required MetaInfo classes from nomad, and additional nomad utilities, e.g., from <code>nomad.atomutils</code>.</p> <pre><code>&lt;license&gt;\nimport os\nimport numpy as np\nimport logging\nfrom nomad.units import ureg\nfrom nomad.parsing.file_parser import FileParser\nfrom nomad.datamodel.metainfo.simulation.run import Run, Program\nfrom nomad.datamodel.metainfo.simulation.method import (\nMethod, ForceField, Model, Interaction, AtomParameters\n)\nfrom nomad.datamodel.metainfo.simulation.system import (\nSystem, Atoms, AtomsGroup\n)\nfrom nomad.datamodel.metainfo.simulation.calculation import (\nCalculation\n)\nfrom nomad.datamodel.metainfo.workflow import (\nWorkflow, MolecularDynamics\n)\nfrom nomad.datamodel.metainfo.simulation import workflow as workflow2\nfrom nomad.atomutils import get_molecules_from_bond_list, is_same_molecule, get_composition\n</code></pre>"},{"location":"computational/#parser-classes","title":"Parser Classes","text":"<pre><code>class &lt;Parsername&gt;&lt;Mainfiletype&gt;Parser(FileParser):\ndef __init__(self):\nsuper().__init__(None)\n@property\ndef file&lt;mainfiletype&gt;(self):\nif self._file_handler is None:\ntry:\nself._file_handler = &lt;openfilefunction&gt;(self.mainfile, 'rb')\nexcept Exception:\nself.logger.error('Error reading &lt;mainfiletype&gt; file.')\nreturn self._file_handler\nclass &lt;Parsername&gt;Parser:\ndef __init__(self):\nself.&lt;mainfiletype&gt;_parser = &lt;Parsername&gt;&lt;Mainfiletype&gt;Parser()\n</code></pre> <p>The main class for your parser, <code>&lt;Parsername&gt;Parser</code>, will contain the bulk of the parsing routine, described further below. It may be useful to create a distinct class, <code>&lt;Parsername&gt;&lt;Mainfiletype&gt;Parser</code>, for dealing with various filetypes that may be parsed throughout the entirety of the routine. However, in the simplest case of a single file type parsed, the entire parser can of course be implemented within a single class.</p> <p>In the following, we will walk through the layout of the <code>&lt;Parsername&gt;Parser</code> class. First, every parser class should have a \"main\" function called <code>parse()</code>, which will be called by NOMAD when the appropriate mainfile is found:</p> <pre><code>def parse(self, filepath, archive, logger):\nself.filepath = os.path.abspath(filepath)\nself.archive = archive\nself.logger = logging.getLogger(__name__) if logger is None else logger\nself._maindir = os.path.dirname(self.filepath)\nself._&lt;parsername&gt;_files = os.listdir(self._maindir)  # get the list of files in the same directory as the mainfile\nself._basename = os.path.basename(filepath).rsplit('.', 1)[0]\nself.init_parser()\nif self.&lt;mainfileparser&gt;_parser is None:\nreturn\nsec_run = self.archive.m_create(Run)\nsec_run.program = Program(name='&lt;PARSERNAME&gt;', version='unknown')\nself.parse_method()\nself.parse_system()\nself.parse_calculation()\nself.parse_workflow()\n</code></pre> <p>Then, the individual functions to populate that various MetaInfo sections can be defined:</p> <pre><code>def parse_calculation(self):\nsec_run = self.archive.run[-1]\nsec_calc = sec_run.m_create(Calculation)\n# populate calculation metainfo\n# ...\ndef parse_system(self, frame):\nsec_run = self.archive.run[-1]\nsec_system = sec_run.m_create(System)\nsec_atoms = sec_system.m_create(Atoms)\n# populate system metainfo\n# ...\ndef parse_method(self, frame):\nsec_method = self.archive.run[-1].m_create(Method)\nsec_force_field = sec_method.m_create(ForceField)\nsec_model = sec_force_field.m_create(Model)\n# populate method metainfo\n# ...\ndef parse_workflow(self):\nsec_workflow = self.archive.m_create(Workflow)  # for old workflow, should update for workflow2\n# populate workflow metainfo\n# ...\n</code></pre> <p>For more information, see Examples - populating the NOMAD archive .</p>"},{"location":"creating_new_metainfo/","title":"Creating new MetaInfo","text":""},{"location":"creating_new_metainfo/#nomad-metainfo","title":"NOMAD MetaInfo","text":""},{"location":"creating_new_metainfo/#code-specific-metainfo","title":"Code-specific MetaInfo","text":""},{"location":"parser_shell/","title":"Creating the shell for your parser","text":"<p>First, create a directory for your parser under the relevant parser project directory:</p> <pre><code>cd dependencies/parsers/&lt;parserproject&gt;\nmkdir &lt;parsername&gt;\n</code></pre> <p>In the following please note the naming conventions:</p> <ul> <li> <p>&lt;parsername&gt; - flat case, e.g., quantumespresso</p> </li> <li> <p>&lt;ParserName&gt; - Pascal case, e.g., QuantumEspresso</p> </li> <li> <p>&lt;parser_name&gt; - snake case, e.g., quantum_espresso</p> </li> <li> <p>&lt;PARSERNAME&gt; - upper flat case, e.g., QUANTUMESPRESSO</p> </li> </ul>"},{"location":"parser_shell/#parser-files","title":"Parser files","text":"<p>In the following, &lt;license&gt; represents the insertion of the following license agreement statement:</p> <pre><code>#\n# Copyright The NOMAD Authors.\n#\n# This file is part of NOMAD.\n# See https://nomad-lab.eu for further info.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n</code></pre> <p>The following are typical files found within a parser source directory:</p> <ul> <li> <p><code>__init__.py</code></p> <pre><code>&lt;license&gt;\nfrom .parser import &lt;ParserName&gt;Parser\n</code></pre> </li> <li> <p><code>__main__.py</code></p> <pre><code>&lt;license&gt;\nimport sys\nimport json\nimport logging\n\nfrom nomad.utils import configure_logging\nfrom nomad.datamodel import EntryArchive\nfrom atomisticparsers.&lt;parsername&gt; import &lt;ParserName&gt;Parser\n\nif __name__ == \"__main__\":\n    configure_logging(console_log_level=logging.DEBUG)\n    archive = EntryArchive()\n    &lt;ParserName&gt;Parser().parse(sys.argv[1], archive, logging)\n    json.dump(archive.m_to_dict(), sys.stdout, indent=2)\n</code></pre> </li> <li> <p><code>metainfo/__init__.py</code></p> <pre><code>&lt;license&gt;\nfrom nomad.metainfo import Environment\n\nfrom . import &lt;parsername&gt;\n\nm_env = Environment()\nm_env.m_add_sub_section(Environment.packages, &lt;parsername&gt;.m_package)\n</code></pre> </li> <li> <p><code>metainfo/&lt;parser_name&gt;.py</code> - contains code-specific metadata definitions.</p> </li> <li> <p><code>nomad_plugin.yaml</code></p> <pre><code>code_category: &lt;Parserproject&gt; code\ncode_homepage: &lt;&gt;\ncode_name: &lt;PARSERNAME&gt;\nmetadata:\ncodeCategory: &lt;Parserproject&gt; code\ncodeLabel: &lt;PARSERNAME&gt;\ncodeLabelStyle: All in capitals\ncodeName: &lt;parsername&gt;\ncodeUrl: &lt;&gt;\nparserDirName: dependencies/parsers/&lt;parserproject&gt;/&lt;parserproject&gt;parsers/parsername/\nparserGitUrl: https://github.com/nomad-coe/&lt;parserproject&gt;-parsers.git\nparserSpecific: ''\npreamble: ''\nstatus: production\ntableOfFiles: ''\nname: parsers/&lt;parsername&gt;\nparser_class_name: &lt;parserproject&gt;parsers.&lt;parsername&gt;.parser.&lt;ParserName&gt;Parser\npython_package: &lt;parserproject&gt;parsers.&lt;parsername&gt;\n</code></pre> </li> <li> <p><code>parser.py</code> - the parser source code.</p> </li> <li> <p><code>README.md</code> - a short description of the functionality of this parser.</p> </li> </ul>"},{"location":"parser_shell/#integration-into-nomads-parser-matching-interface","title":"Integration into NOMAD's parser-matching interface","text":"<p>The <code>nomad_plugin.yaml</code> file enables the parser to be recognized as a plugin to the NOMAD software. However, in order for NOMAD to identify that it should use this parser, we still need to add configuration details within NOMAD's parser-matching interface. These options are specified within the plugins options (<code>plugins = Plugins(options={}))</code>)  in the file <code>nomad/config/__init__.py</code>. There are many examples to follow here. In short, we need to create a dictionary key within <code>options</code> for our new parser:</p> <pre><code>'parsers/&lt;parsername&gt;': Parser(\n    python_package='&lt;parserproject&gt;parsers.&lt;parsername&gt;',\n    &lt;args&gt;\n    )\n</code></pre> <p>Here, <code>&lt;args&gt;</code> can be one or several of the following:</p> <ul> <li><code>mainfile_name_re=</code> - regex string for matching mainfile name</li> <li><code>mainfile_contents_re=</code> - regex string for matching mainfile contents</li> <li><code>mainfile_mime_re=</code> -</li> <li><code>supported_compressions=</code> -</li> <li><code>mainfile_alternative=</code> -</li> <li><code>mainfile_binary_header_re=</code> -</li> <li><code>mainfile_contents_dict={'__has_all_keys': ['&lt;key1&gt;', '&lt;key2&gt;'}),</code></li> <li><code>parser_as_interface=</code> -</li> </ul> <p>You can find further information about this topic here: Examples of parser-matching</p>"},{"location":"parser_tests/","title":"Creating parser tests","text":"<p>Each parser should have a series of associated (py)tests to ensure that future developments do not affect the intended parsing. These tests can be found under directly under  <code>&lt;parserproject&gt;/tests/</code> directory, labeled by the corresponding parser name: <code>test_parsername.py</code>.</p> <p>Here is an example template of such a <code>pytest</code> code: <pre><code>&lt;license&gt;\n\nimport pytest\nimport numpy as np\n\nfrom nomad.datamodel import EntryArchive\nfrom &lt;parserproject&gt;.&lt;parsername&gt; import ParserName\n\ndef approx(value, abs=0, rel=1e-6):\n    return pytest.approx(value, abs=abs, rel=rel)\n\n@pytest.fixture(scope='module')\ndef parser():\n    return &lt;ParserName&gt;()\n\ndef test_parser(parser):\n    archive = EntryArchive()\n    parser.parse(&lt;path_to_test_mainfile&gt;, archive, None)\n\n    sec_run = archive.run[0]\n\n    assert sec_run.program.name == '&lt;PARSERNAME&gt;'\n    assert sec_run.program.version == 'x.x.x'\n\n    sec_method = sec_run.method\n    assert len(sec_method) == 1\n    assert len(sec_method[0].force_field.model[0].contributions) == 1127\n    assert sec_method[0].force_field.model[0].contributions[0].type == 'angle'\n\n    sec_systems = sec_run.system\n    assert len(sec_systems) == 2\n    assert np.shape(sec_systems[0].atoms.positions) == (1516, 3)\n    assert sec_systems[1].atoms.positions[800][1].magnitude == approx(2.4740036e-09)\n    assert sec_systems[0].atoms.velocities[500][0].magnitude == approx(869.4773)\n    assert sec_systems[1].atoms.lattice_vectors[2][2].magnitude == approx(2.469158e-09)\n\n    sec_calc = sec_run.calculation\n    assert len(sec_calc) == 5\n    assert sec_calc[3].temperature.magnitude == approx(291.80401611328125)\n    assert sec_calc[0].energy.total.value.magnitude == approx(-1.1863129365544755e+31)\n\n    sec_workflow = archive.workflow2\n    assert sec_workflow.m_def.name == 'WorkflowName'\n</code></pre></p> <p>The data for your tests should be stored in: <code>&lt;path_to_test_mainfile&gt; = &lt;parserproject&gt;/tests/data/&lt;parsername&gt;</code>. Ideally, there should be an <code>assert</code> statement for each MetaInfo quantity that is populated with your parser.</p>"},{"location":"references/advanced_new_parser_project/","title":"Creating a new parser project","text":""},{"location":"references/examples_parser_matching/","title":"Examples of NOMAD's parser-matching interface","text":""},{"location":"references/examples_populating_archive/","title":"Examples of populating the NOMAD archive","text":""},{"location":"references/old_docs/","title":"How to write a parser","text":"<p>NOMAD uses parsers to convert raw code input and output files into NOMAD's common Archive format. This is documentation on how to develop such a parser.</p>"},{"location":"references/old_docs/#getting-started","title":"Getting started","text":"<p>Let's assume we need to write a new parser from scratch.</p> <p>First we need the install nomad-lab Python package to get the necessary libraries: <pre><code>pip install nomad-lab\n</code></pre></p> <p>We prepared an example parser project that you can work with. <pre><code>git clone https://github.com/nomad-coe/nomad-parser-example.git --branch hello-world\n</code></pre></p> <p>Alternatively, you can fork the example project on GitHub to create your own parser. Clone your fork accordingly.</p> <p>The project structure should be <pre><code>example/exampleparser/__init__.py\nexample/exampleparser/__main__.py\nexample/exampleparser/metainfo.py\nexample/exampleparser/parser.py\nexample/LICENSE.txt\nexample/README.md\nexample/setup.py\n</code></pre></p> <p>Next you should install your new parser with pip. The <code>-e</code> parameter installs the parser in development. This means you can change the sources without the need to re-install. <pre><code>cd example\npip install -e .\n</code></pre></p> <p>The main code file <code>exampleparser/parser.py</code> should look like this: <pre><code>class ExampleParser(MatchingParser):\ndef __init__(self):\nsuper().__init__(name='parsers/example', code_name='EXAMPLE')\ndef run(self, mainfile: str, archive: EntryArchive, logger):\n# Log a hello world, just to get us started. TODO remove from an actual parser.\nlogger.info('Hello World')\nrun = archive.m_create(Run)\nrun.program_name = 'EXAMPLE'\n</code></pre></p> <p>A parser is a simple program with a single class in it. The base class <code>MatchingParser</code> provides the necessary interface to NOMAD. We provide some basic information about our parser in the constructor. The main function <code>run</code> simply takes a filepath and empty archive as input. Now its up to you, to open the given file and populate the given archive accordingly. In the plain hello world, we simple create a log entry and populate the archive with a root section <code>Run</code> and set the program name to <code>EXAMPLE</code>.</p> <p>You can run the parser with the included <code>__main__.py</code>. It takes a file as argument and you can run it like this: <pre><code>python -m exampleparser tests/data/example.out\n</code></pre></p> <p>The output should show the log entry and the minimal archive with one <code>section_run</code> and the respective <code>program_name</code>. <pre><code>INFO     root                 2020-12-02T11:00:52 Hello World\n- nomad.release: devel\n- nomad.service: unknown nomad service\n{\n\"section_run\": [\n{\n\"program_name\": \"EXAMPLE\"\n}\n]\n}\n</code></pre></p>"},{"location":"references/old_docs/#parsing-test-files","title":"Parsing test files","text":"<p>Let's do some actual parsing. Here we demonstrate how to parse ASCII files with some structure information in it. As it is typically used by materials science codes.</p> <p>The on the <code>master</code> branch of the example project, we have a more 'realistic' example: <pre><code>git checkout master\n</code></pre></p> <p>This example imagines a potential code output that looks like this (<code>tests/data/example.out</code>): <pre><code>2020/05/15\n               *** super_code v2 ***\n\nsystem 1\n--------\nsites: H(1.23, 0, 0), H(-1.23, 0, 0), O(0, 0.33, 0)\nlatice: (0, 0, 0), (1, 0, 0), (1, 1, 0)\nenergy: 1.29372\n\n*** This was done with magic source                                ***\n***                                x\u00b042                            ***\n\nsystem 2\n--------\nsites: H(1.23, 0, 0), H(-1.23, 0, 0), O(0, 0.33, 0)\ncell: (0, 0, 0), (1, 0, 0), (1, 1, 0)\nenergy: 1.29372\n</code></pre></p> <p>There is some general information at the top and then a list of simulated systems with sites and lattice describing crystal structures, a computed energy value, an example for a code specific quantity from a 'magic source'.</p> <p>In order to convert the information  from this file into the archive, we first have to parse the necessary quantities: the date, system, energy, etc. The nomad-lab Python package provides a <code>text_parser</code> module for declarative text file parsing. You can define text file parsers like this: <pre><code>def str_to_sites(string):\nsym, pos = string.split('(')\npos = np.array(pos.split(')')[0].split(',')[:3], dtype=float)\nreturn sym, pos\ncalculation_parser = UnstructuredTextFileParser(quantities=[\nQuantity('sites', r'([A-Z]\\([\\d\\.\\, \\-]+\\))', str_operation=str_to_sites),\nQuantity(\nSystem.lattice_vectors,\nr'(?:latice|cell): \\((\\d)\\, (\\d), (\\d)\\)\\,?\\s*\\((\\d)\\, (\\d), (\\d)\\)\\,?\\s*\\((\\d)\\, (\\d), (\\d)\\)\\,?\\s*',\nrepeats=False),\nQuantity('energy', r'energy: (\\d\\.\\d+)'),\nQuantity('magic_source', r'done with magic source\\s*\\*{3}\\s*\\*{3}\\s*[^\\d]*(\\d+)', repeats=False)])\nmainfile_parser = UnstructuredTextFileParser(quantities=[\nQuantity('date', r'(\\d\\d\\d\\d\\/\\d\\d\\/\\d\\d)', repeats=False),\nQuantity('program_version', r'super\\_code\\s*v(\\d+)\\s*', repeats=False),\nQuantity(\n'calculation', r'\\s*system \\d+([\\s\\S]+?energy: [\\d\\.]+)([\\s\\S]+\\*\\*\\*)*',\nsub_parser=calculation_parser,\nrepeats=True)\n])\n</code></pre></p> <p>The quantities to be parsed can be specified as a list of <code>Quantity</code> objects with a name and a regular expression (re) pattern. The matched value should be enclosed in a group(s) denoted by <code>(...)</code>. By default, the parser uses the findall method of <code>re</code>, hence overlap between matches is not tolerated. If overlap cannot be avoided, one should switch to the finditer method by passing findall=False to the parser. Multiple matches for the quantity are returned if repeats=True (default). The name, data type, shape and unit for the quantity can also intialized by passing a metainfo Quantity. An external function str_operation can be also be passed to perform more specific string operations on the matched value. A local parsing on a matched block can be carried out by nesting a sub_parser. This is also an instance of the <code>UnstructuredTextFileParser</code> with a list of quantities to parse. To access a parsed quantity, one can use the get method.</p> <p>We can apply these parser definitions like this: <pre><code>mainfile_parser.mainfile = mainfile\nmainfile_parser.parse()\n</code></pre></p> <p>This will populate the <code>mainfile_parser</code> object with parsed data and it can be accessed like a Python dict with quantity names as keys: <pre><code>run = archive.m_create(Run)\nrun.program_name = 'super_code'\nrun.program_version = str(mainfile_parser.get('program_version'))\ndate = datetime.datetime.strptime(\nmainfile_parser.get('date'),\n'%Y/%m/%d') - datetime.datetime(1970, 1, 1)\nrun.program_compilation_datetime = date.total_seconds()\nfor calculation in mainfile_parser.get('calculation'):\nsystem = run.m_create(System)\nsystem.lattice_vectors = calculation.get('lattice_vectors')\nsites = calculation.get('sites')\nsystem.atom_labels = [site[0] for site in sites]\nsystem.atom_positions = [site[1] for site in sites]\nscc = run.m_create(SCC)\nscc.single_configuration_calculation_to_system_ref = system\nscc.energy_total = calculation.get('energy') * units.eV\nscc.single_configuration_calculation_to_system_ref = system\nmagic_source = calculation.get('magic_source')\nif magic_source is not None:\nscc.x_example_magic_value = magic_source\n</code></pre></p> <p>You can still run the parse on the given example file: <pre><code>python -m exampleparser tests/data/example.out\n</code></pre></p> <p>Now you should get a more comprehensive archive with all the provided information from the <code>example.out</code> file.</p> <p>** TODO more examples an explanations for: unit conversion, logging, types, scalar, vectors, multi-line matrices **</p>"},{"location":"references/old_docs/#extending-the-metainfo","title":"Extending the Metainfo","text":"<p>The NOMAD Metainfo defines the schema of each archive. There are pre-defined schemas for all domains (e.g. <code>common_dft.py</code> for electron-structure codes; <code>common_ems.py</code> for experiment data, etc.). The sections <code>Run</code>, <code>System</code>, an single configuration calculations (<code>SCC</code>) in the example are taken fom <code>common_dft.py</code>. While this covers most data that is usually provide in code input/output files, some data is typically format specific and only applies to a certain code or method. For these cases, we allow to extend the Metainfo like this (<code>exampleparser/metainfo.py</code>): <pre><code># We extend the existing common definition of a section \"single configuration calculation\"\nclass ExampleSCC(SCC):\n# We alter the default base class behavior to add all definitions to the existing\n# base class instead of inheriting from the base class\nm_def = Section(extends_base_section=True)\n# We define an additional example quantity. Use the prefix x_&lt;parsername&gt;_ to denote\n# non common quantities.\nx_example_magic_value = Quantity(type=int, description='The magic value from a magic source.')\n</code></pre></p>"},{"location":"references/old_docs/#testing-a-parser","title":"Testing a parser","text":"<p>Until now, we simply run our parse on some example data and manually observed the output. To improve the parser quality and ease the further development, you should get into the habit of testing the parser.</p> <p>We use the Python unit test framework pytest: <pre><code>pip install pytest\n</code></pre></p> <p>A typical test, would take one example file, parse it, and make assertions about the output. <pre><code>def test_example():\nparser = rExampleParser()\narchive = EntryArchive()\nparser.run('tests/data/example.out', archive, logging)\nrun = archive.section_run[0]\nassert len(run.section_system) == 2\nassert len(run.section_single_configuration_calculation) == 2\nassert run.section_single_configuration_calculation[0].x_example_magic_value == 42\n</code></pre></p> <p>You can run all tests in the <code>tests</code> directory like this: <pre><code>pytest -svx tests\n</code></pre></p> <p>You should define individual test cases with example files that demonstrate certain features of the underlying code/format.</p>"},{"location":"references/old_docs/#structured-data-files-with-numpy","title":"Structured data files with numpy","text":"<p>TODO: examples</p> <p>The <code>DataTextParser</code> uses the numpy.loadtxt function to load an structured data file. The loaded data can be accessed from property data.</p>"},{"location":"references/old_docs/#xml-parser","title":"XML Parser","text":"<p>TODO: examples</p> <p>The <code>XMLParser</code> uses the ElementTree module to parse an xml file. The parse method of the parser takes in an xpath style key to access individual quantities. By default, automatic data type conversion is performed, which can be switched off by setting convert=False.</p>"},{"location":"references/old_docs/#add-the-parser-to-nomad","title":"Add the parser to NOMAD","text":"<p>NOMAD has to manage multiple parsers and during processing needs to decide what parsers to run on what files. To decide what parser is use, NOMAD processing relies on specific parser attributes.</p> <p>Consider the example, where we use the <code>MatchingParser</code> constructor to add additional attributes that determine for what files the parser is indented: <pre><code>class ExampleParser(MatchingParser):\ndef __init__(self):\nsuper().__init__(\nname='parsers/example', code_name='EXAMPLE', code_homepage='https://www.example.eu/',\nmainfile_mime_re=r'(application/.*)|(text/.*)',\nmainfile_contents_re=(r'^\\s*#\\s*This is example output'))\n</code></pre></p> <ul> <li><code>mainfile_mime_re</code>: A regular expression on the mime type of files. The parser is only run on files with matching mime type. The mime-type is guessed with libmagic.</li> <li><code>mainfile_contents_re</code>: A regular expression that is applied to the first 4k of a file. The parser is only run on files where this matches.</li> <li><code>mainfile_name_re</code>: A regular expression that can be used to match against the name and path of the file.</li> </ul> <p>Not all of these attributes have to be used. Those that are given must all match in order to use the parser on a file.</p> <p>The nomad infrastructure keep a list of parser objects (in <code>nomad/parsing/parsers.py::parsers</code>). These parser are considered in the order they appear in the list. The first matching parser is used to parse a given file.</p> <p>While each parser project should provide its own tests, a single example file should be added to the infrastructure parser tests (<code>tests/parsing/test_parsing.py</code>).</p> <p>Once the parser is added, it become also available through the command line interface and normalizers are applied as well: <pre><code>nomad parser tests/data/example.out\n</code></pre></p>"},{"location":"references/old_docs/#developing-an-existing-parser","title":"Developing an existing parser","text":"<p>To develop an existing parser, you should install all parsers: <pre><code>pip install nomad-lab[parsing]\n</code></pre></p> <p>Close the parser project on top: <pre><code>git clone &lt;parser-project-url&gt;\ncd &lt;parser-dir&gt;\n</code></pre></p> <p>Either remove the installed parser and pip install the cloned version: <pre><code>rm -rf &lt;path-to-your-python-env&gt;/lib/python3.7/site-packages/&lt;parser-module-name&gt;\npip install -e .\n</code></pre></p> <p>Or use <code>PYTHONPATH</code> so that the cloned code takes precedence over the installed code: <pre><code>PYTHONPATH=. nomad parser &lt;path-to-example-file&gt;\n</code></pre></p> <p>Alternatively, you can also do a full developer setup of the NOMAD infrastructure and develop the parser there.</p>"},{"location":"references/quick_NOMAD_best_practices/","title":"Quick guide for best practices for NOMAD development","text":""},{"location":"references/quick_installing_nomad_dev/","title":"Quick start to installing a development version of NOMAD","text":"<p>Detailed instructions can be found here: Developing NOMAD.</p> <p>The NOMAD repository is located on the MPCDF gitlab. To collaborate on the project, you will first need an invitation. You can send invitation requests to <code>fairmat@physik.hu-berlin.de</code>.</p> <p>Once you have access to MPCDF gitlab:</p> <p>Clone the NOMAD gitlab repo and navigate to the resulting directory:</p> <pre><code>git clone https://gitlab.mpcdf.mpg.de/nomad-lab/nomad-FAIR.git nomad\ncd nomad/\n</code></pre> <p>You should be on the branch <code>origin/develop</code> by default. Create a virtual environment for your nomad installation:</p> <pre><code>pip install virtualenv\nvirtualenv -p `which python3` .pyenv\nsource .pyenv/bin/activate\n</code></pre> <p>Now install nomad:</p> <pre><code>./scripts/setup_dev_env.sh\n</code></pre>"},{"location":"references/quick_parser_setup/","title":"Quick start for setting up a local parser","text":""},{"location":"references/standard_workflows/","title":"Standard workflows in NOMAD","text":""}]}